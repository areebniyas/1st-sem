{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4164F2sxJBE"
      },
      "outputs": [],
      "source": [
        "# Import required libraries.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding, SpatialDropout1D\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Import libraries for text pre processing.\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "_69uK9EGxJBH",
        "outputId": "67d5adec-d95e-4ed1-c225-2656b04f0e90"
      },
      "outputs": [],
      "source": [
        "# Read dataset.\n",
        "df_twitter = pd.read_csv('train.csv')\n",
        "print(df_twitter.head())\n",
        "print(df_twitter.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot the distribution of the target variable.\n",
        "plt.pie(df_twitter['label'].value_counts(), labels=['Non-hate', 'Hate'], autopct='%1.1f%%', shadow=True, startangle=90)\n",
        "plt.title('Distribution of tweets')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print number of values for each class.\n",
        "class_count = df_twitter['label'].value_counts()\n",
        "\n",
        "# Print number of hate and non-hate tweets.\n",
        "print('Number of hate tweets: {}'.format(class_count[1]))\n",
        "print('Number of non-hate tweets: {}'.format(class_count[0]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWMbfl_AxJBI",
        "outputId": "3c06ac73-5cb5-4136-fdec-d1432e48e141"
      },
      "outputs": [],
      "source": [
        "# Check for null values.\n",
        "print(df_twitter.isnull().sum())\n",
        "\n",
        "# Drop columns that are not required.\n",
        "df_twitter.drop('id',axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VN4twJeUxJBJ"
      },
      "outputs": [],
      "source": [
        "# Read another dataset\n",
        "df_offensive=pd.read_csv(\"labeled_data.csv\")\n",
        "\n",
        "# Drop columns that are not required.\n",
        "df_offensive.drop(['Unnamed: 0','count','hate_speech','offensive_language','neither'],axis=1,inplace=True)\n",
        "df_offensive.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print number of values for each class.\n",
        "class_counts = df_offensive['class'].value_counts()\n",
        "\n",
        "# Print the names and corresponding counts for each class/target variable.\n",
        "for class_label, count in class_counts.items():\n",
        "    if class_label == 1:\n",
        "        class_name = 'neither'\n",
        "    elif class_label == 0:\n",
        "        class_name = 'hate'\n",
        "    elif class_label == 2:\n",
        "        class_name = 'offensive'\n",
        "    else:\n",
        "        class_name = 'unknown'  # Handle other cases if necessary\n",
        "\n",
        "    print(f'{class_name}: {count}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnLDKgUbxJBK",
        "outputId": "09c0e32d-13ac-49af-ca56-4e5a7ee2b618"
      },
      "outputs": [],
      "source": [
        "df_offensive['class'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "mwqifJQlxJBK",
        "outputId": "ff98994b-647b-4073-aca2-0dbb4105c143"
      },
      "outputs": [],
      "source": [
        "df_offensive[df_offensive['class']==0]['class']=1\n",
        "df_offensive.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJheh5cgxJBL",
        "outputId": "b7910dfa-d08b-47f0-e88e-02043a245210"
      },
      "outputs": [],
      "source": [
        "df_offensive['class'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "jCvn2_cDxJBL",
        "outputId": "b93ce2bd-5c7d-4bf6-bdf8-8ba9b0a884a1"
      },
      "outputs": [],
      "source": [
        "df_offensive[df_offensive['class']==0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZMEPfUvxJBL"
      },
      "outputs": [],
      "source": [
        "df_offensive[\"class\"].replace({0: 1}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3_Fm1nixJBL",
        "outputId": "d22ad47a-8d43-48ff-b163-1890669fb25a"
      },
      "outputs": [],
      "source": [
        "df_offensive['class'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "d2da7cVOxJBL",
        "outputId": "89fb3b57-2b50-4c41-a7bf-0e0f8c344bfe"
      },
      "outputs": [],
      "source": [
        "df_offensive[df_offensive['class']==0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "D1D8dKPOxJBL",
        "outputId": "8e102a12-14f3-4699-f652-0fb1129309ce"
      },
      "outputs": [],
      "source": [
        "df_offensive[\"class\"].replace({2: 0}, inplace=True)\n",
        "df_offensive.rename(columns ={'class':'label'}, inplace = True)\n",
        "df_offensive.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ffJaa_ZAxJBM",
        "outputId": "600fa39c-218d-4831-b5c9-f4bb26869580"
      },
      "outputs": [],
      "source": [
        "df_offensive.iloc[0]['tweet']\n",
        "df_offensive.iloc[5]['tweet']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "-flEUpgZxJBM",
        "outputId": "38d5f353-33da-4bfe-ee99-0023469f4c53"
      },
      "outputs": [],
      "source": [
        "frame=[df_twitter,df_offensive]\n",
        "df = pd.concat(frame)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot the distribution of the target variable in new dataframe.\n",
        "plt.pie(df['label'].value_counts(), labels=['Non-hate', 'Hate'], autopct='%1.1f%%', shadow=True, startangle=90)\n",
        "plt.title('Distribution of tweets')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# print number of hate and non-hate tweets.\n",
        "class_count = df['label'].value_counts()\n",
        "print('Number of hate tweets: {}'.format(class_count[1]))\n",
        "print('Number of non-hate tweets: {}'.format(class_count[0]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBKOdLSyxJBM",
        "outputId": "e8c5426d-14fc-4851-b2b1-4cfd89fba3e5"
      },
      "outputs": [],
      "source": [
        "stemmer = nltk.SnowballStemmer(\"english\")\n",
        "stopword=set(stopwords.words('english'))\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "    Cleans the given text by converting it to lowercase, removing symbols in square brackets,\n",
        "    removing URLs, removing HTML tags, removing punctuation, removing newline characters,\n",
        "    removing words containing numbers, removing stopwords, and stemming words.\n",
        "\n",
        "    Args:\n",
        "        text (str): The text to be cleaned.\n",
        "\n",
        "    Returns:\n",
        "        str: The cleaned text.\n",
        "    \"\"\"\n",
        "    text = str(text).lower() # Convert to lowercase.\n",
        "    text = re.sub('\\[.*?\\]', '', text) # Remove symbols in square brackets.\n",
        "    text = re.sub('https?://\\S+|www\\.\\S+', '', text) # Remove URLs.\n",
        "    text = re.sub('<.*?>+', '', text) # Remove HTML tags.\n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text) # Remove punctuation.\n",
        "    text = re.sub('\\n', '', text) # Remove newline characters.\n",
        "    text = re.sub('\\w*\\d\\w*', '', text) # Remove words containing numbers.\n",
        "    text = [word for word in text.split(' ') if word not in stopword] # Remove stopwords.\n",
        "    text=\" \".join(text) # Join list of words in to a string separated by space.\n",
        "    text = [stemmer.stem(word) for word in text.split(' ')] # Stem words.\n",
        "    text=\" \".join(text) # Join list of words in to a string separated by space.\n",
        "    return text\n",
        "\n",
        "# Clean the text in the dataset.\n",
        "df['tweet']=df['tweet'].apply(clean_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "YQasnykSxJBM",
        "outputId": "60c0119b-6c36-462f-b377-30406f2226f0"
      },
      "outputs": [],
      "source": [
        "# Print the last 5 rows of the dataset.\n",
        "df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Word cloud for non-hate tweets.\n",
        "from wordcloud import WordCloud\n",
        "plt.figure(figsize=(20,20))\n",
        "wc = WordCloud(max_words = 2000 , width = 1600 , height = 800).generate(\" \".join(df[df.label == 0].tweet))\n",
        "plt.imshow(wc , interpolation = 'bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vy6dKlGwxJBM",
        "outputId": "57580ee5-9ef6-4666-f286-8d286e6ed68c"
      },
      "outputs": [],
      "source": [
        "# Input data.\n",
        "x=df['tweet']\n",
        "\n",
        "# Target variable.\n",
        "y=df['label']\n",
        "\n",
        "# Split the data into training and testing sets.\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=42)\n",
        "print(len(x_train), len(y_train))\n",
        "print(len(x_test), len(y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYSqg_uvxJBM",
        "outputId": "694fd4cc-d7e8-4d45-c319-ea3bc2fe3ca1"
      },
      "outputs": [],
      "source": [
        "# Vectorize the text data using CountVectorizer.\n",
        "count = CountVectorizer(stop_words='english', ngram_range=(1,5))\n",
        "\n",
        "# Fit and transform the training data using CountVectorizer.\n",
        "x_train_vectorizer=count.fit_transform(x_train)\n",
        "# Transform the test data using the fitted CountVectorizer.\n",
        "x_test_vectorizer=count.transform(x_test)\n",
        "# Convert the training data to a dense array representation.\n",
        "x_train_vectorizer.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDkhyKrqxJBM"
      },
      "outputs": [],
      "source": [
        "# Transform data using TF-IDF transformer.\n",
        "tfidf = TfidfTransformer()\n",
        "\n",
        "# Fit and transform the training data using TF-IDF transformer.\n",
        "x_train_tfidf = tfidf.fit_transform(x_train_vectorizer)\n",
        "# Transform the test data using the fitted TF-IDF transformer.\n",
        "x_train_tfidf.toarray()\n",
        "x_test_tfidf = tfidf.transform(x_test_vectorizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znpGLOAhyTJG"
      },
      "source": [
        "Train and build model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzM8bODjyXCS"
      },
      "outputs": [],
      "source": [
        "# Tokenize the text data.\n",
        "max_words = 50000\n",
        "max_len = 300\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(x_train)\n",
        "# Convert the text data to sequence.\n",
        "sequences = tokenizer.texts_to_sequences(x_train)\n",
        "# Pads the sequences to ensure same length.\n",
        "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wWVNfR_yaXx",
        "outputId": "fede0215-9899-4f68-ee72-6dc90bd24426"
      },
      "outputs": [],
      "source": [
        "# Build a LSTM model.\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_words, 100, input_length=max_len))\n",
        "model.add(SpatialDropout1D(0.2))\n",
        "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()\n",
        "\n",
        "# Compile the model.\n",
        "model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UO37Gc3jyil1"
      },
      "outputs": [],
      "source": [
        "# Define early stopping to prevent overfitting.\n",
        "es = EarlyStopping(\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    patience=5\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ynz7gwpYyj_A",
        "outputId": "768b58aa-c1b6-4fa2-c264-c12caaa3b64e"
      },
      "outputs": [],
      "source": [
        "# Train the model.\n",
        "history=model.fit(sequences_matrix,y_train,batch_size=1024,epochs=10,\n",
        "          validation_split=0.2,callbacks=[es])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJOMrEuoyuN9"
      },
      "outputs": [],
      "source": [
        "# Process the test data by converting it into sequences and padding them.\n",
        "test_sequences = tokenizer.texts_to_sequences(x_test)\n",
        "test_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5B2kEK_3I9z",
        "outputId": "3d064a7f-4a94-4585-c4ce-3ee4caf779b9"
      },
      "outputs": [],
      "source": [
        "# Check accuracy of model on test data.\n",
        "accuracy = model.evaluate(test_sequences_matrix,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSZB69iR3Nqt",
        "outputId": "5afc0e86-d11d-4b9b-c0e4-b9b0f131777f"
      },
      "outputs": [],
      "source": [
        "lstm_prediction=model.predict(test_sequences_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Making a single prediction\n",
        "new_tweet = 'I hate you'\n",
        "new_tweet = clean_text(new_tweet)\n",
        "new_tweet = tokenizer.texts_to_sequences([new_tweet])\n",
        "new_tweet = sequence.pad_sequences(new_tweet, maxlen=max_len)\n",
        "prediction = model.predict(new_tweet)\n",
        "if(prediction>0.5):\n",
        "    print(\"Hate speech\")\n",
        "else:\n",
        "    print(\"Non hate speech\")\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the model\n",
        "model.save('lstm_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot the accuracy and loss of the model.\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train','Validation'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot the training and validation loss.\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train','Validation'], loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print the confusion matrix using seaborn and colors.\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "cm = confusion_matrix(y_test, lstm_prediction.round())\n",
        "plt.figure(figsize=(5,5))\n",
        "sns.heatmap(cm, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r')\n",
        "plt.ylabel('Actual label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print f1 score.\n",
        "from sklearn.metrics import f1_score\n",
        "print('F1 score: {}'.format(f1_score(y_test, lstm_prediction.round())))\n",
        "\n",
        "# Print precision score.\n",
        "from sklearn.metrics import precision_score\n",
        "print('Precision score: {}'.format(precision_score(y_test, lstm_prediction.round())))\n",
        "\n",
        "# Print recall score.\n",
        "from sklearn.metrics import recall_score\n",
        "print('Recall score: {}'.format(recall_score(y_test, lstm_prediction.round())))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print ROC curve.\n",
        "from sklearn.metrics import roc_curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, lstm_prediction)\n",
        "plt.plot([0,1],[0,1],'k--')\n",
        "plt.plot(fpr,tpr, label='LSTM')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print the auc score.\n",
        "from sklearn.metrics import auc\n",
        "auc_score=auc(fpr,tpr)\n",
        "print('AUC score: {}'.format(auc_score))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print evaluation metrics.\n",
        "from sklearn.metrics import classification_report\n",
        "report = classification_report(y_test, lstm_prediction.round(), target_names = ['Non-hate','Hate'])\n",
        "print(report)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
